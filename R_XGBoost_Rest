###########################################################################
#################### IMPORTA LIBS E DEFINE ################################
###########################################################################
gc()
rm(list = ls())
library(caret)
library(car)
library(C50)
library(ISLR)
library(xgboost)
library(MatrixModels)
library(Matrix)
library(gmodels)
library(e1071)
library(devtools)
library(parallel)
library(doParallel)
library(Information)
library(InformationValue)
library(ROCR)
library(dplyr)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
###########################################################################
#################### IMPORTO BASE E TRATO VARIAVEIS #######################
###########################################################################
mydirectory = "MyDirectory"
AF_RAIZ     <- read.csv(file = paste(mydirectory,
                                     "BASE_AF_10X.csv", sep = "\\"),
                        sep = ";", 
                        stringsAsFactors = FALSE)
AF_RAIZ$STATUS_N        <- as.numeric(AF_RAIZ$STATUS_N)
x <- substr(AF_RAIZ$SAFRA_EVENTO_MES,1,2)
y <- substr(AF_RAIZ$SAFRA_EVENTO_MES,3,5)
z <- substr(AF_RAIZ$SAFRA_EVENTO_MES,6,9)
AF_RAIZ$SAFRA_EVENTO_MES<- lubridate::ymd(paste0(year  = z, 
                                                 month = y, 
                                                 day   = x))
#### CONFIDENTIAL CODE ####
rm(x,
   y,
   z)
###########################################################################
#################### SELECIONA AMOSTRAGEM #################################
###########################################################################
str(AF_RAIZ)
set.seed(666)
AF_RAIZ_random  <- AF_RAIZ[order(runif(NROW(AF_RAIZ))), ]
AF_treino_valid <- subset(AF_RAIZ_random, SAFRA_EVENTO_MES != '2018-12-01') 
smp_siz         <- floor(0.75*nrow(AF_treino_valid))
for_train       <- sample(seq_len(nrow(AF_treino_valid)), size = smp_siz)

AF_treino     <- AF_treino_valid[for_train, ]
AF_validacao  <- AF_treino_valid[-for_train, ]

teste         <- subset(AF_RAIZ_random,SAFRA_EVENTO_MES=='2018-12-01')
teste_1       <- subset(teste, STATUS_N == 1)
teste_0       <- subset(teste, STATUS_N == 0)
smp_siz       <- floor(0.18*nrow(teste_0))
for_train     <- sample(seq_len(nrow(teste_0)), size = smp_siz)
AF_teste_0    <- teste_0[for_train,]
AF_teste      <- rbind(teste_1,AF_teste_0)
AF_teste      <- AF_teste[,]

#CHECO SE A PROPORCAO DAS BASES EST�O CORRETA:
prop.table(table(AF_RAIZ$STATUS_N))
prop.table(table(AF_treino$STATUS_N))
prop.table(table(AF_validacao$STATUS_N))
prop.table(table(AF_teste$STATUS_N))
rm(AF_RAIZ_random,
   AF_treino_valid,
   smp_siz,
   for_train,
   teste,
   teste_1,
   teste_0,
   AF_teste_0)
###########################################################################
#################### AJUSTO OS CAMPOS #####################################
###########################################################################
for (i in 1:NCOL(AF_treino))
  AF_treino[,i]     <- as.numeric(AF_treino[,i])
for (i in 1:NCOL(AF_validacao))
  AF_validacao[,i]  <- as.numeric(AF_validacao[,i])
for (i in 1:NCOL(AF_teste))
  AF_teste[,i]      <- as.numeric(AF_teste[,i])
AF_treino$SAFRA_EVENTO_MES    <- as.Date(AF_treino$SAFRA_EVENTO_MES, 
                                         origin = "1970-01-01")
AF_validacao$SAFRA_EVENTO_MES <- as.Date(AF_validacao$SAFRA_EVENTO_MES, 
                                         origin = "1970-01-01")
AF_teste$SAFRA_EVENTO_MES     <- as.Date(AF_teste$SAFRA_EVENTO_MES, 
                                         origin = "1970-01-01")

###########################################################################
#################### CONFIGURO PRIMEIRA XGBOOST ###########################
###########################################################################
AF_xgb <- xgboost(data            = data.matrix(AF_treino[,c(-1,-2,-3)]),
                  label           = AF_treino$STATUS_N,
                  verbose         = 0,    #define avisos como ligado
                  booster         = 'gblinear',
                  eta             = 0.002,     #melhor � 0.003: preven��o contra overfitting - VALORES T�PICOS: [0.01, 0.2]
                  objective       = 'binary:logistic',
                  eval_metric     = 'error',  #erro correto para class.bin.
                  nrounds         = 300,
                  seed            = 666)
importance <- xgb.importance(model = AF_xgb)
importance$ajustado <- abs(importance$Weight)
importance$'%' <- importance$ajustado/sum(importance$ajustado)
importance$'% acum' <- importance[1,4]
for(i in 2:nrow(importance))
{
  importance[i,5] <- importance[i,4] + importance [i-1,5]
}
pdf(file = paste(mydirectory,
                 "1_Importancia_100.pdf",
                 sep = "\\"),
    width=6,
    height=6)
xgb.plot.importance(importance,
                    rel_to_first = FALSE,
                    main = "Importancia das Variaveis - 100%",
                    xlab = "Importancia na Resposta")
dev.off()
rm(AF_xgb)

###########################################################################
#################### CONFIGURO SEGUNDA XGBOOST ############################
###########################################################################
to.remove <- subset(importance, `% acum` > 0.95)
AF_treino <- AF_treino[, !colnames(AF_treino) %in% to.remove$Feature]
AF_validacao <- AF_validacao[, !colnames(AF_validacao) %in% to.remove$Feature]
AF_teste <- AF_teste[, !colnames(AF_teste) %in% to.remove$Feature]

AF_xgb <- xgboost(data            = data.matrix(AF_treino[,c(-1,-2,-3)]),
                  label           = AF_treino$STATUS_N,
                  verbose         = 0,    #define avisos como ligado
                  booster         = 'gblinear',
                  eta             = 0.04,     #melhor � 0.003: preven��o contra overfitting - VALORES T�PICOS: [0.01, 0.2]
                  objective       = 'binary:logistic',
                  eval_metric     = 'error',  #erro correto para class.bin.
                  nrounds         = 300,
                  seed            = 666)
importance <- xgb.importance(model = AF_xgb)
importance$ajustado <- abs(importance$Weight)
importance$'%' <- importance$ajustado/sum(importance$ajustado)
importance$'% acum' <- importance[1,4]
for(i in 2:nrow(importance))
{
  importance[i,5] <- importance[i,4] + importance [i-1,5]
}
pdf(file = paste(mydirectory,
                 "2_Importancia_95.pdf",
                 sep = "\\"),
    width=6,
    height=6)
xgb.plot.importance(importance,
                    rel_to_first = FALSE,
                    main = "Importancia das Variaveis - 95%",
                    xlab = "Importancia na Resposta")
dev.off()
rm(to.remove,
   importance)
###########################################################################
#################### PREDI��O DA XGBOOST ##################################
###########################################################################
AF_treino$SCORE <- NULL
AF_treino$SCORE <- predict(AF_xgb,
                           data.matrix(AF_treino[,c(-1,-2,-3)]),
                           type = "prob")

AF_validacao$SCORE <- NULL
AF_validacao$SCORE <- predict(AF_xgb,
                              data.matrix(AF_validacao[,c(-1,-2,-3)]),
                              type = "prob")

AF_teste$SCORE <- NULL
AF_teste$SCORE <- predict(AF_xgb,
                          data.matrix(AF_teste[,c(-1,-2,-3)]),
                          type = "prob")
rm(AF_xgb)
###########################################################################
#################### AVALIA A PERFORMANCE DO MODELO #######################
###########################################################################
pred_xgb_treino <- prediction(AF_treino$SCORE,
                              AF_treino$STATUS_N)
ROC_treino <-ROCR::performance(pred_xgb_treino,
                               measure = "tpr",
                               x.measure = "fpr")
ks_treino   <- max(attr(ROC_treino,
                        "y.values")[[1]] - (attr(ROC_treino,
                                                 "x.values")[[1]]))

pred_xgb_valid <- prediction(AF_validacao$SCORE,
                             AF_validacao$STATUS_N)
ROC_valid <-ROCR::performance(pred_xgb_valid,
                              measure = "tpr",
                              x.measure = "fpr")
ks_valid   <- max(attr(ROC_valid,
                       "y.values")[[1]] - (attr(ROC_valid,
                                                "x.values")[[1]]))

pred_xgb_teste <- prediction(AF_teste$SCORE,
                             AF_teste$STATUS_N)
ROC_teste <-ROCR::performance(pred_xgb_teste,
                              measure = "tpr",
                              x.measure = "fpr")
ks_teste <- max(attr(ROC_teste,
                     "y.values")[[1]] - (attr(ROC_teste,
                                              "x.values")[[1]]))

ks_treino
ks_valid
ks_teste
rm(pred_xgb_treino,
   pred_xgb_valid)
###########################################################################
#################### PLOTA GR�FICOS #######################################
###########################################################################
pdf(file = paste(mydirectory,
                 "3_ROC_Curves.pdf",
                 sep = "\\"),
    width=6,
    height=6)
plot(ROC_teste,
     col = "blue",
     main=paste0('KS Treino = ',
                 round(ks_treino*100,1),
                 '% - KS Valid. = ',
                 round(ks_valid*100,1),
                 '% - KS Teste = ',
                 round(ks_teste*100,1),'%'))
plot(ROC_treino,
     add = TRUE,
     col = "red")
plot(ROC_valid,
     add = TRUE,
     col = "yellow")
lines(x=c(0,1),
      y=c(0,1))
dev.off()
rm(ks_treino,
   ks_valid,
   ks_teste,
   ROC_treino,
   ROC_valid,
   ROC_teste)
###########################################################################
#################### CALCULA AUC - AREA UNDER the CURVE ###################
###########################################################################
ROC.auc <- performance(pred_xgb_teste,measure = "auc")
unlist(ROC.auc@y.values)
rm(ROC.auc,
   pred_xgb_teste)
###########################################################################
#################### CALCULA ESTABILIDADE DO KS ###########################
###########################################################################
ks_vector <- NULL
interaction_vector <- NULL
for(i in 1:200)
{
  base.teste.ks <- sample_n(AF_treino, 0.05*nrow(AF_treino), replace =TRUE)
  AF_xgb <- xgboost(data            = data.matrix(base.teste.ks[,c(-1,-2,-3)]),
                    label           = base.teste.ks$STATUS_N,
                    verbose         = 0,    #define avisos como off
                    booster         = 'gblinear',
                    eta             = 0.04,     #melhor � 0.003: preven��o contra overfitting - VALORES T�PICOS: [0.01, 0.2]
                    objective       = 'binary:logistic',
                    eval_metric     = 'error',  #erro correto para class.bin.
                    nrounds         = 300,
                    seed            = 666)
  pred_treino_teste.ks <- predict(AF_xgb,
                                  data.matrix(base.teste.ks[,c(-1,-2,-3)]),
                                  type = "prob")
  pred_xgb_treino_teste.ks <- prediction(pred_treino_teste.ks,
                                         base.teste.ks$STATUS_N)
  ROC_treino_teste.ks <-ROCR::performance(pred_xgb_treino_teste.ks,
                                          measure = "tpr",
                                          x.measure = "fpr")
  ks_treino_teste.ks   <- max(attr(ROC_treino_teste.ks,
                                   "y.values")[[1]] - (attr(ROC_treino_teste.ks,
                                                            "x.values")[[1]]))
  ks_vector          <- rbind(ks_vector,
                              ks_treino_teste.ks)
  interaction_vector <- rbind(interaction_vector,
                              i)
  print(i)
}
ks.base <- data.frame('ks'=ks_vector, 'interaction'=interaction_vector)
ks.base
pdf(file = paste(mydirectory,
                 "4_Distribui��o_KS_Treino.pdf",
                 sep = "\\"),
    width=6,
    height=6)
plot(ks.base$ks,
     type = "l",
     main = paste0("Distribui��o KS x 200 amostras de Treino"),
     xlab = "N�mero da Intera��o",
     ylab = "KS",
     ylim = c(0,1),
     xlim = c(min(ks.base$interaction), max(ks.base$interaction)))
dev.off()


ks_vector <- NULL
interaction_vector <- NULL
for(i in 1:200)
{
  base.teste.ks <- sample_n(AF_treino, 0.05*nrow(AF_treino), replace =TRUE)
  AF_xgb <- xgboost(data            = data.matrix(base.teste.ks[,c(-1,-2,-3)]),
                    label           = base.teste.ks$STATUS_N,
                    verbose         = 0,    #define avisos como off
                    booster         = 'gblinear',
                    eta             = 0.04,     #melhor � 0.003: preven��o contra overfitting - VALORES T�PICOS: [0.01, 0.2]
                    objective       = 'binary:logistic',
                    eval_metric     = 'error',  #erro correto para class.bin.
                    nrounds         = 300,
                    seed            = 666)
  pred_valid_teste.ks <- predict(AF_xgb,
                                 data.matrix(base.teste.ks[,c(-1,-2,-3)]),
                                 type = "prob")
  pred_xgb_valid_teste.ks <- prediction(pred_valid_teste.ks,
                                        base.teste.ks$STATUS_N)
  ROC_valid_teste.ks <-ROCR::performance(pred_xgb_valid_teste.ks,
                                         measure = "tpr",
                                         x.measure = "fpr")
  ks_valid_teste.ks   <- max(attr(ROC_valid_teste.ks,
                                  "y.values")[[1]] - (attr(ROC_valid_teste.ks,
                                                           "x.values")[[1]]))
  ks_vector          <- rbind(ks_vector,
                              ks_valid_teste.ks)
  interaction_vector <- rbind(interaction_vector,
                              i)
  print(i)
}
ks.base <- data.frame('ks'=ks_vector, 'interaction'=interaction_vector)
ks.base
pdf(file = paste(mydirectory,
                 "5_Distribui��o_KS_Validacao.pdf",
                 sep = "\\"),
    width=6,
    height=6)
plot(ks.base$ks,
     type = "l",
     main = paste0("Distribui��o KS x 200 amostras de Validacao"),
     xlab = "N�mero da Intera��o",
     ylab = "KS",
     ylim = c(0,1),
     xlim = c(min(ks.base$interaction), max(ks.base$interaction)))
dev.off()
rm(ks_vector,
   interaction_vector,
   base.teste.ks,
   AF_xgb,
   pred_xgb_treino_teste.ks,
   pred_xgb_valid_teste.ks,
   ROC_treino_teste.ks,
   ROC_valid_teste.ks,
   ks_treino_teste.ks,
   ks_valid_teste.ks,
   ks.base)
###########################################################################
#################### PREPARA ALAVANCAGEM '#################################
###########################################################################
Alavancagem_Treino_RESTO <- AF_treino %>% 
  mutate(FX_SCORE = ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[2],"J",
                           ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[3],"I",
                                  ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[4],"H",
                                         ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[5],"G",
                                                ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[6],"F",
                                                       ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[7],"E",
                                                              ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[8],"D",
                                                                     ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[9],"C",
                                                                            ifelse(AF_treino$SCORE <= quantile(AF_treino$SCORE, prob = seq(0,1,length=11),type = 5)[10],"B","A")))))))))) %>% 
  group_by(FX_SCORE) %>% 
  summarise(qtd_tot = n(),
            mix = n()/nrow(AF_treino),
            qtd_bom = sum(STATUS_N == 1, na.rm = T),
            qtd_mau = sum(STATUS_N == 0, na.rm = T)) %>%
  mutate(ODD = (qtd_bom/sum(qtd_bom))/(qtd_mau/sum(qtd_mau)))

Alavancagem_Valid_RESTO <- AF_validacao %>% 
  mutate(FX_SCORE = ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[2],"J",
                           ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[3],"I",
                                  ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[4],"H",
                                         ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[5],"G",
                                                ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[6],"F",
                                                       ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[7],"E",
                                                              ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[8],"D",
                                                                     ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[9],"C",
                                                                            ifelse(AF_validacao$SCORE <= quantile(AF_validacao$SCORE, prob = seq(0,1,length=11),type = 5)[10],"B","A")))))))))) %>% 
  group_by(FX_SCORE) %>% 
  summarise(qtd_tot = n(),
            mix = n()/nrow(AF_validacao),
            qtd_bom = sum(STATUS_N == 1, na.rm = T),
            qtd_mau = sum(STATUS_N == 0, na.rm = T)) %>%
  mutate(ODD = (qtd_bom/sum(qtd_bom))/(qtd_mau/sum(qtd_mau)))

Alavancagem_Teste_RESTO <- AF_teste %>% 
  mutate(FX_SCORE = ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[2],"J",
                           ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[3],"I",
                                  ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[4],"H",
                                         ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[5],"G",
                                                ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[6],"F",
                                                       ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[7],"E",
                                                              ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[8],"D",
                                                                     ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[9],"C",
                                                                            ifelse(AF_teste$SCORE <= quantile(AF_teste$SCORE, prob = seq(0,1,length=11),type = 5)[10],"B","A")))))))))) %>% 
  group_by(FX_SCORE) %>% 
  summarise(qtd_tot = n(),
            mix = n()/nrow(AF_teste),
            qtd_bom = sum(STATUS_N == 1, na.rm = T),
            qtd_mau = sum(STATUS_N == 0, na.rm = T))  %>%
  mutate(ODD = (qtd_bom/sum(qtd_bom))/(qtd_mau/sum(qtd_mau)))

P_mau_RESTOcum_treino <- NULL
P_bom_RESTOcum_treino <- NULL
P_mau_RESTOcum_valid <- NULL
P_bom_RESTOcum_valid <- NULL
P_mau_RESTOcum_teste <- NULL
P_bom_RESTOcum_teste <- NULL
KS_treino <- NULL
KS_valid <- NULL
KS_teste <- NULL
for(i in 1:10)
{
  P_mau_RESTOcum_treino[i] <- sum(Alavancagem_Treino_RESTO[1:i,5])/sum(Alavancagem_Treino_RESTO[1:10,5])
  P_mau_RESTOcum_valid[i] <- sum(Alavancagem_Valid_RESTO[1:i,5])/sum(Alavancagem_Valid_RESTO[1:10,5])
  P_mau_RESTOcum_teste[i] <- sum(Alavancagem_Teste_RESTO[1:i,5])/sum(Alavancagem_Teste_RESTO[1:10,5])
  
  P_bom_RESTOcum_treino[i] <- sum(Alavancagem_Treino_RESTO[1:i,4])/sum(Alavancagem_Treino_RESTO[1:10,4])
  P_bom_RESTOcum_valid[i] <- sum(Alavancagem_Valid_RESTO[1:i,4])/sum(Alavancagem_Valid_RESTO[1:10,4])
  P_bom_RESTOcum_teste[i] <- sum(Alavancagem_Teste_RESTO[1:i,4])/sum(Alavancagem_Teste_RESTO[1:10,4])
  
  KS_treino[i] <- -P_mau_RESTOcum_treino[i] + P_bom_RESTOcum_treino[i]
  KS_valid[i] <- -P_mau_RESTOcum_valid[i] + P_bom_RESTOcum_valid[i] 
  KS_teste[i] <- -P_mau_RESTOcum_teste[i] + P_bom_RESTOcum_teste[i] 
}
Alavancagem_Treino_RESTO$'%mau acum' <- P_mau_RESTOcum_treino
Alavancagem_Treino_RESTO$'%bom acum' <- P_bom_RESTOcum_treino
Alavancagem_Treino_RESTO$'KS' <- KS_treino

Alavancagem_Valid_RESTO$'%mau acum' <- P_mau_RESTOcum_valid
Alavancagem_Valid_RESTO$'%bom acum' <- P_bom_RESTOcum_valid
Alavancagem_Valid_RESTO$'KS' <- KS_valid

Alavancagem_Teste_RESTO$'%mau acum' <- P_mau_RESTOcum_teste
Alavancagem_Teste_RESTO$'%bom acum' <- P_bom_RESTOcum_teste
Alavancagem_Teste_RESTO$'KS' <- KS_teste

write.csv(Alavancagem_Treino_RESTO,
          file = paste(mydirectory,
                       "ALAVANCAGEM_TREINO_RESTO.csv",
                       sep = "\\"))
write.csv(Alavancagem_Valid_RESTO,
          file = paste(mydirectory,
                       "ALAVANCAGEM_VALIDACAO_RESTO.csv",
                       sep = "\\"))
write.csv(Alavancagem_Teste_RESTO,
          file = paste(mydirectory,
                       "ALAVANCAGEM_TESTE_RESTO.csv",
                       sep = "\\"))
rm(Alavancagem_Treino_RESTO,
   Alavancagem_Valid_RESTO,
   Alavancagem_Teste_RESTO)
stopCluster(cluster)
